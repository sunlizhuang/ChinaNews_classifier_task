Author: Gary Sands, Wikistrat

The latest Programme for International Student Assessment (PISA) results released at the end of 2019 seem to be another big win for China’s education system. The Paris-based Organisation for Economic Co-operation and Development (OECD) conducts the test every three years and this year’s results include some 600,000 students from 79 countries.

The mostly computer-based tests focus on reading, mathematics, science and global competence — skills that prepare young people to thrive in a more inter-connected world. Chinese students from Beijing, Shanghai, Jiangsu and Zhejiang took up top honours.

China and other Asia Pacific nations performed well, confirming the notion that high value is placed on education by governments and parents in the Asia Pacific. This includes the long hours dedicated to rote memorisation by students and the general reverence of teachers. But beyond the popularity of evening ‘cram schools’, the pressure to succeed can often lead to the cutting of corners.

Allegations about the fixing of grades by teachers and pupils in 2013 caused a riot at a Chinese school after invigilators tried to halt brazen exam fraud. The abundance of cheating more broadly raises questions about the validity of PISA results, and how Chinese students seemingly came out on top.

Instead of choosing one consistent geographical entity, PISA allows a representative sample of at least 150 schools for each participating country or education system — allowing some education administrators to select top-performing students from smaller samples. Shanghai was China’s sole representative sample in the two previous PISA tests in 2009 and 2012.

After compiling the test results, students from Shanghai finished at the top of all three subject areas tested. Such cherry-picking is also evident in this year’s inclusion of Zhejiang province over Guangdong. This may have played some role in the uncharacteristic increase in China’s test score.

The OECD is well aware of past criticism over the use of representative samples. It attempts to address these concerns in its most recent report, arguing that ‘[the] four provinces/municipalities in eastern China far from represent China as a whole, but the size of each of them compares to that of a typical OECD country’.

If educational administrators in the United States used the same logic used for the ‘B-S-J-Z [China] grouping’, the United States could be represented by Massachusetts, Maryland, California and Connecticut — the top four states with the best high schools. In the 2015 PISA test, a separate score was calculated for Massachusetts, which as a stand-alone result would have resulted in the country taking first place in reading, second place in science and 12th place in mathematics.

Beyond the obvious tampering with geographic classification, PISA samples allow results to be cherry-picked from the very best schools. Each country submits a sampling frame to a research firm ‘taking into account factors such as location and level of education’.

In the second stage, roughly 42 students are then selected from each school to sit the assessment, with some otherwise-eligible students potentially ‘excluded for reasons including the remoteness and inaccessibility of their school, intellectual or physical disability, a lack of proficiency in the test language, or a lack of test material in the language of instruction’.

Since each country or education system is responsible for selecting schools to be sampled, there is the possibility that some administrators might have chosen the very best students from the best schools to participate in the PISA test. In China’s case, an exception has been made for their educational administrators to pool results from four provinces or municipalities.

If the goal of PISA is ‘to provide useful information to educators and policymakers concerning the strengths and weaknesses of their country’s education system, the progress made over time, and opportunities for improvement’, then the real danger in releasing flawed results is the complacency it encourages when addressing the huge educational disparities between provinces in China.

Some two-thirds of all Chinese children live in rural areas (sometimes left under the care of grandparents by parents seeking employment in cities) where, according to the Rural Education Action Program at Stanford University, high school attendance rates are as low as 40 per cent.

China’s system of household registration (hukou) further exacerbates the educational disparities between rich and poor, as many migrant workers are unable to enrol their children in schools outside of their hometown. While great strides have been taken to educate China’s population in science, only 8.5 per cent of the Chinese population have an ‘understanding’ of science and can use it to solve problems.

While difficult to administer fairly, the PISA test is a worthwhile effort to draw attention to opportunities for improvement in the educational systems of many countries. But by allowing China’s educators to manipulate the results, the OECD is kowtowing to Beijing and compromising the integrity of its results.

Gary Sands is a Senior Analyst at Wikistrat and a Director at Highway West Capital Advisors.